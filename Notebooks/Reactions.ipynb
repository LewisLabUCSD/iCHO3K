{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "907aceed",
   "metadata": {},
   "source": [
    "# Reactions\n",
    "This notebook contains all the steps followed in order to reconcile the existing metabolic reconstruction in CHO cells. It si divided into two parts: **1. Network Reconstruction** and **2. Identification of duplicated reactions**\n",
    "\n",
    "[1. Network Reconstruction](#reconstruction) <br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;**1.1 Datasets generation and merge**<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;**1.2 Normalization of the data** <br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;**1.3 Group all the data into a unified dataset** <br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;**1.4 Addition of the Recon3D CHO ortholog GPRs into the reconstruction** <br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;**1.5 Divide the dataset in two to facilitate reading and curation in Google Sheets** <br>\n",
    "\n",
    "[2. Identification of Duplicated Reactions](#duplicated) <br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;**2.1 Generate the model and identify duplicated reactions**<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;**2.2 Fix duplicated reactions in the dataset from the list duplicated_reactions obtained above** <br>\n",
    "\n",
    "[3. Add Database links and Pre-checks to \"Rxns\" and \"Attributes\" Sheet](#bigg) <br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;**3.1 Add BiGG and EBI links to the \"Rxns\" and \"Attributes\" Sheets**<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;**3.2 Add a \"Pre-check\" tag to the Rxns Sheet** <br>\n",
    "\n",
    "[4. Subsystem Reorganization](#subsystem) <br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;**4.1 Update Transport reactions**<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;**4.2 Update iCHO1766 Reactions Subsystem**<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;**4.3 Manual Standarization of Subsystems**<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;**4.4 Check for differences in the Subsystems of the Reconstrction and Systems datasets** <br>\n",
    "\n",
    "[5. Manual Curation Metrics](#curation) <br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;**5.1 Calculate the amount of reactions in _max tier_**<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;**5.2 Calculate the amount of reactions in _medium tier_** <br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;**5.3 Calculate the amount of reactions in _basic tier 1_** <br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;**5.4 Calculate the amount of reactions in _basic tier 2_** <br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;**5.5 Plot a Pie Chart with the amount of reactions in each tier**\n",
    "\n",
    "[6. Addition of Kcat values added by Meiyas' team](#kcat) <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0896294",
   "metadata": {},
   "source": [
    "## 1. Network Reconstruction <a id='reconstruction'></a>\n",
    "These include the generation of datasets (1), normalization of the data (2), merging all four reconstructions into a unified dataset (3), compiling the generated reconstruction into a cobra model in order to identify duplicated reactions (4), fixing duplicated reactions using BiGG ID annotation (5), adding Recon3D GPR information (6), and finally dividing the dataset into two different datasets that will be further curated in Google Sheets (7)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450f12c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries import\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ce2b55",
   "metadata": {},
   "source": [
    "### 1.1 Datasets generation and merge\n",
    "Dataset generation from previous reconstructions (CHO_DG44, iCHO1766, iCHO2101, iCHO2291)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f9ff72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read excel files and create the dfs\n",
    "\n",
    "#Camels CHO_DG44 metabolic reconstruction\n",
    "camel_df = pd.read_excel('../Data/Reconciliation/datasets/CHO_DG44.xlsx', header = 1)\n",
    "\n",
    "#Hefzi's iCHO1766 metabolic reconstruction\n",
    "hefzi_df = pd.read_excel('../Data/Reconciliation/datasets/hefzi_final.xlsx')\n",
    "\n",
    "#Foudaliha's iCHO2101 metabolic reconstruction\n",
    "fouladiha_df = pd.read_excel('../Data/Reconciliation/datasets/iCHO2101.xlsx', 'Supplementary Table 10', header = 1)\n",
    "\n",
    "#Yeo's iCHO2291 metabolic reconstruction\n",
    "iCHO2291 = pd.read_excel('../Data/Reconciliation/datasets/iCHO2291_final.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0eca726",
   "metadata": {},
   "source": [
    "### 1.2 Normalization of the data\n",
    "All dataset are normalized into the same shape and format and then combined into one big dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745a3124",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standarization of the columns names\n",
    "camel_df.rename(columns = {'Reaction ID':'Reaction', 'Initial reaction in model':'Reaction Formula', 'Reaction name':'Reaction Name', 'Justification':'Curation Notes'}, inplace = True)\n",
    "fouladiha_df.rename(columns = {'Abbreviation':'Reaction', 'Description':'Reaction Name', 'Reaction':'Reaction Formula', 'GPR':'GPR_fou'}, inplace = True)\n",
    "\n",
    "# Addition of tag columns for organizational purposes\n",
    "camel_df.insert(loc=0, column='cam', value='X')\n",
    "camel_df.insert(loc=1, column='hef', value=np.nan)\n",
    "camel_df.insert(loc=2, column='fou', value=np.nan)\n",
    "camel_df.insert(loc=3, column='yeo', value=np.nan)\n",
    "\n",
    "hefzi_df.insert(loc=0, column='cam', value=np.nan)\n",
    "hefzi_df.insert(loc=1, column='hef', value='X')\n",
    "hefzi_df.insert(loc=2, column='fou', value=np.nan)\n",
    "hefzi_df.insert(loc=3, column='yeo', value=np.nan)\n",
    "\n",
    "fouladiha_df.insert(loc=0, column='cam', value=np.nan)\n",
    "fouladiha_df.insert(loc=1, column='hef', value=np.nan)\n",
    "fouladiha_df.insert(loc=2, column='fou', value='X')\n",
    "fouladiha_df.insert(loc=3, column='yeo', value=np.nan)\n",
    "\n",
    "iCHO2291.insert(loc=0, column='cam', value=np.nan)\n",
    "iCHO2291.insert(loc=1, column='hef', value=np.nan)\n",
    "iCHO2291.insert(loc=2, column='fou', value=np.nan)\n",
    "iCHO2291.insert(loc=3, column='yeo', value='X')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a6ae9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate cols list with the column names from all datasets\n",
    "cols = hefzi_df.columns.to_list()+fouladiha_df.columns.to_list()+iCHO2291.columns.to_list()+camel_df.columns.to_list()\n",
    "\n",
    "# Eliminate repetitive values in the 'cols' list\n",
    "cols = [cols[i] for i in range(len(cols)) if i == cols.index(cols[i])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381c546e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_col(df):\n",
    "    '''\n",
    "    This function adds the columns from the cols list \n",
    "    that are not present in the df\n",
    "    '''\n",
    "    df.columns\n",
    "    add_col = []\n",
    "    for col in cols:\n",
    "        if col not in df.columns:\n",
    "            add_col.append(col)\n",
    "    df = df.reindex(columns = df.columns.tolist() + add_col)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcad1b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unify columns for all datasets\n",
    "hefzi_df = add_col(hefzi_df)\n",
    "fouladiha_df = add_col(fouladiha_df)\n",
    "iCHO2291 = add_col(iCHO2291)\n",
    "camel_df = add_col(camel_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ec5b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reorder columns in all datasets the same way\n",
    "fouladiha_df = fouladiha_df[['cam','hef', 'fou', 'yeo', 'Reaction', 'Reaction Name', 'Reaction Formula', 'GPR_hef','GPR_fou','GPR_yeo', 'Subsystem', 'Genes', 'Protein', 'EC Number', 'Mol wt', 'kcat_forward', 'kcat_backward', 'Reversible','Lower bound', 'Upper bound', 'Objective', 'Curation Notes', 'References', 'Reaction ID Camels Models']]\n",
    "iCHO2291 = iCHO2291[['cam','hef', 'fou', 'yeo', 'Reaction', 'Reaction Name', 'Reaction Formula', 'GPR_hef','GPR_fou','GPR_yeo', 'Subsystem', 'Genes', 'Protein', 'EC Number', 'Mol wt', 'kcat_forward', 'kcat_backward', 'Reversible','Lower bound', 'Upper bound', 'Objective', 'Curation Notes', 'References', 'Reaction ID Camels Models']]\n",
    "hefzi_df = hefzi_df[['cam','hef', 'fou', 'yeo', 'Reaction', 'Reaction Name', 'Reaction Formula', 'GPR_hef','GPR_fou','GPR_yeo', 'Subsystem', 'Genes', 'Protein', 'EC Number', 'Mol wt', 'kcat_forward', 'kcat_backward', 'Reversible','Lower bound', 'Upper bound', 'Objective', 'Curation Notes', 'References', 'Reaction ID Camels Models']]\n",
    "camel_df = camel_df[['cam','hef', 'fou', 'yeo', 'Reaction', 'Reaction Name', 'Reaction Formula', 'GPR_hef','GPR_fou','GPR_yeo', 'Subsystem', 'Genes', 'Protein', 'EC Number', 'Mol wt', 'kcat_forward', 'kcat_backward', 'Reversible','Lower bound', 'Upper bound', 'Objective', 'Curation Notes', 'References', 'Reaction ID Camels Models']]\n",
    "\n",
    "camel_df['Reaction'] = camel_df['Reaction'].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203bbe97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge all the dfs into a unified df\n",
    "all_dfs = pd.concat([camel_df, hefzi_df, fouladiha_df, iCHO2291])\n",
    "all_dfs = all_dfs.reset_index(drop = True)\n",
    "\n",
    "#Unify reaction names\n",
    "all_dfs['Reaction'] = all_dfs['Reaction'].str.replace('_cho', '')\n",
    "all_dfs['Reaction'] = all_dfs['Reaction'].str.replace(r\"(e)\", \"_e_\", regex = False)\n",
    "all_dfs['Reaction'] = all_dfs['Reaction'].str.replace(\"[\", \"_\")\n",
    "all_dfs['Reaction'] = all_dfs['Reaction'].str.replace(\"]\", \"_\")\n",
    "\n",
    "all_dfs #20940 rows/reactions (many of them repeated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044513b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the underscore at the end of some reactions\n",
    "\n",
    "rxns = []\n",
    "idx = []\n",
    "\n",
    "for i,row in all_dfs.iterrows():\n",
    "    if str(row['Reaction']).endswith('_'):\n",
    "        s = re.sub('_$', '', row['Reaction'])\n",
    "        rxns.append(s)\n",
    "        idx.append(i)\n",
    "        \n",
    "all_dfs['Reaction'].update(pd.Series(rxns,index=idx))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8119e796",
   "metadata": {},
   "source": [
    "### 1.3 Group all the data into a unified dataset\n",
    "The combined dataset generated above \"all_dfs\" is grouped by the Reaction BiGG ID to obtain a dataset with unique reaction identifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111e4043",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the data into a unified dataset\n",
    "\n",
    "all_dfs2 = all_dfs.groupby('Reaction').first()\n",
    "all_dfs2['Reaction Formula'] = all_dfs2['Reaction Formula'].str.replace('[','_')\n",
    "all_dfs2['Reaction Formula'] = all_dfs2['Reaction Formula'].str.replace(']','')\n",
    "all_dfs2['Reaction Formula'] = all_dfs2['Reaction Formula'].str.replace(' => | =>',' --> ')\n",
    "all_dfs2['Reaction Formula'] = all_dfs2['Reaction Formula'].str.replace(' <-- | <--',' <=> ')\n",
    "all_dfs2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3861e5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate Demand Reaccion into a different df and remove from reconstruction. \n",
    "# Keep demand reactions from extracellular space\n",
    "\n",
    "all_dfs2 = all_dfs2.reset_index()\n",
    "demand_reactions = pd.DataFrame(columns = all_dfs2.columns)\n",
    "\n",
    "for index, rxn in all_dfs2.iterrows():\n",
    "    rxn = rxn['Reaction Formula']\n",
    "    a,b = re.split('<=>|-->',rxn)\n",
    "    if (b == '' or b == ' ') and not a.endswith('_e '):\n",
    "        temp_df = all_dfs2[all_dfs2['Reaction Formula'] == rxn]\n",
    "        demand_reactions = pd.concat([demand_reactions,temp_df])\n",
    "        all_dfs2.drop(index, inplace=True)\n",
    "\n",
    "demand_reactions = demand_reactions.reset_index(drop=True)\n",
    "demand_reactions.to_excel('../Data/Reconciliation/datasets/demand_reactions.xlsx')\n",
    "demand_reactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a3f34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dfs2 = all_dfs2.reset_index(drop=True)\n",
    "all_dfs2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af7ae59",
   "metadata": {},
   "source": [
    "### 1.4 Addition of the Recon3D CHO ortholog GPRs into the reconstruction\n",
    "The information from the dataset generated in the notebook \"GPR Annotation\" containing all the information from Recon3D GPRS in human and its corresponding CHO orthologs is mapped into our reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19817d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a dict with recon3d reactions as keys and the CHO GPRs as values.\n",
    "recon3d = pd.read_excel('../Data/GPR_Curation/recon3D_chogprs.xlsx')\n",
    "recon3d_dict = recon3d.set_index('m_reaction')['CHO GPR'].to_dict()\n",
    "recon3d_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9af3bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map 'recon3d_dict' into the all_dfs3 dataframe\n",
    "# the reaction IDs should be the same as those in our reconstruction\n",
    "\n",
    "all_dfs3 = all_dfs2.reset_index()\n",
    "all_dfs3['GPR_Recon3D'] = all_dfs3['Reaction'].map(recon3d_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd24a607",
   "metadata": {},
   "source": [
    "### 1.5 Divide the dataset in two to facilitate reading and curation in Google Sheets\n",
    "The dataset all_dfs3 is divided into two different datasets: all_dfs4 contains mainly all the information regarding GPRs assigned from previous reconstructions. all_dfs5 contains the rest of the attributes in the reconstruction such as EC number, bounds, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90db5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_dfs4 contains mainly information of the reactions GPRs\n",
    "all_dfs4 = all_dfs3[['Reaction', 'Reaction Name', 'Reaction Formula', 'Subsystem', 'GPR_hef', 'GPR_fou', 'GPR_yeo', 'GPR_Recon3D', 'Curation Notes', 'References']]\n",
    "all_dfs4.insert(8,'GPR_final', '')\n",
    "all_dfs4.to_excel('../Data/Reconciliation/datasets/all_dfs4.xlsx')\n",
    "all_dfs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65952ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_dfs5 contains information of the rest of the attributes in our reconstruction\n",
    "all_dfs5 = all_dfs3[['Reaction', 'Genes', 'Protein', 'EC Number', 'Mol wt', 'kcat_forward', 'kcat_backward', 'Reversible', 'Lower bound', 'Upper bound', 'Objective']]\n",
    "all_dfs5.to_excel('../Data/Reconciliation/datasets/all_dfs5.xlsx')\n",
    "all_dfs5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb752ef7",
   "metadata": {},
   "source": [
    "## 2. Identifications of Duplicated Reactions <a id='duplicated'></a>\n",
    "In this part of the notebook we use the **duplicated_reactions** fucntion from the **utils** module to spot duplicated reactions in our dataset. First we generate a model, using cobprapy, with our dataset, then we apply the **duplicated_reactions** function to the model, and finally we standarize the name of the duplicated reactions according to the nomenclature used in BiGG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36be791",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries import\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "from requests_html import HTMLSession\n",
    "from tqdm.notebook import tqdm\n",
    "from cobra import Model, Reaction, Metabolite, util\n",
    "\n",
    "from utils import duplicated_reactions\n",
    "from google_sheet import GoogleSheet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93bd8ed0",
   "metadata": {},
   "source": [
    "### 2.1 Generate the model and identify duplicated reactions\n",
    "Generation of a cobra model from the **Google Sheet dataset**. This model will be used to identify duplicated reactions from the stoichiometric matrix of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9c0f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the necessary datasets for the identification of the duplicated reactions\n",
    "KEY_FILE_PATH = 'credentials.json'\n",
    "SPREADSHEET_ID_v3 = '1MlBXeHIKw8k8fZyXm-sN__AHTRSunJxar_-bqvukZws'\n",
    "\n",
    "# Initialize the GoogleSheet object\n",
    "sheet = GoogleSheet(SPREADSHEET_ID_v3, KEY_FILE_PATH)\n",
    "\n",
    "# Read data from the Google Sheet\n",
    "sheet_rxns = 'Rxns'\n",
    "sheet_attributes = 'Attributes'\n",
    "\n",
    "reactions = sheet.read_google_sheet(sheet_rxns)\n",
    "rxns_attributes = sheet.read_google_sheet(sheet_attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2bcdfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### ----- Create a model from the reactions sheet ----- #####\n",
    "model = Model(\"iCHO\")\n",
    "lr = []\n",
    "for _, row in reactions.iterrows():\n",
    "    r = Reaction(row['Reaction'])\n",
    "    lr.append(r)    \n",
    "model.add_reactions(lr)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00893fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### ----- Add information to each one of the reactions ----- #####\n",
    "for i,r in enumerate(tqdm(model.reactions)):\n",
    "    print(r.id)\n",
    "    r.build_reaction_from_string(reactions['Reaction Formula'][i])\n",
    "    r.name = reactions['Reaction Name'][i]\n",
    "    r.subsystem = reactions['Subsystem'][i]\n",
    "    r.lower_bound = float(rxns_attributes['Lower bound'][i])\n",
    "    r.upper_bound = float(rxns_attributes['Upper bound'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442ff757",
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicated_reactions = duplicated_reactions(model)\n",
    "duplicated_reactions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d684b4",
   "metadata": {},
   "source": [
    "### 2.2 Fix duplicated reactions in the dataset from the list duplicated_reactions obtained above\n",
    "Duplicated reactions are itereated in a for loop and mapped in the original dataset. A request is made in the \n",
    "BiGG database http://bigg.ucsd.edu with each of the duplicated reactions. If any of the duplicated reactions is in BiGG, the other reaction automatically changes its name to the one located in Bigg. This way we unifiy the names of our reactions to those in BiGG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3cae52",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for rxn in tqdm(duplicated_reactions):\n",
    "    \n",
    "    session = HTMLSession()\n",
    "    \n",
    "    response=session.get('http://bigg.ucsd.edu/models/iCHOv1/reactions/'+reactions['Reaction'][rxn[0]])\n",
    "    if response.status_code == 200:\n",
    "        if reactions['Reaction'][rxn[0]] == rxns_attributes['Reaction'][rxn[0]] and reactions.loc[rxn[1], 'Reaction'] == rxns_attributes.loc[rxn[1], 'Reaction']:\n",
    "            print(f'1 Reaction {reactions.iloc[rxn[1],6]} changed for {reactions.iloc[rxn[0],6]} present in CHOv1 model')\n",
    "            reactions.loc[rxn[1], 'Reaction'] = reactions['Reaction'][rxn[0]]\n",
    "            rxns_attributes.loc[rxn[1], 'Reaction'] = rxns_attributes['Reaction'][rxn[0]]\n",
    "            i += 1\n",
    "    \n",
    "    elif response.status_code != 200:\n",
    "        response=session.get('http://bigg.ucsd.edu/models/iCHOv1/reactions/'+reactions['Reaction'][rxn[1]])\n",
    "        if response.status_code == 200:\n",
    "            if reactions['Reaction'][rxn[0]] == rxns_attributes['Reaction'][rxn[0]] and reactions.loc[rxn[1], 'Reaction'] == rxns_attributes.loc[rxn[1], 'Reaction']:\n",
    "                print(f'2 Reaction {reactions.iloc[rxn[0],6]} changed for {reactions.iloc[rxn[1],6]} present in CHOv1 model')\n",
    "                reactions.loc[rxn[0], 'Reaction'] = reactions['Reaction'][rxn[1]]\n",
    "                rxns_attributes.loc[rxn[0], 'Reaction'] = rxns_attributes['Reaction'][rxn[1]]\n",
    "                i += 1\n",
    "            \n",
    "        elif response.status_code != 200:\n",
    "            response=session.get('http://bigg.ucsd.edu/universal/reactions/'+reactions['Reaction'][rxn[0]])\n",
    "            if response.status_code == 200:\n",
    "                if reactions['Reaction'][rxn[0]] == rxns_attributes['Reaction'][rxn[0]] and reactions.loc[rxn[1], 'Reaction'] == rxns_attributes.loc[rxn[1], 'Reaction']:\n",
    "                    print(f'3 Reaction {reactions.iloc[rxn[1],6]} changed for {reactions.iloc[rxn[0],6]} present BiGG database')\n",
    "                    reactions.loc[rxn[1], 'Reaction'] = reactions['Reaction'][rxn[0]]\n",
    "                    rxns_attributes.loc[rxn[1], 'Reaction'] = rxns_attributes['Reaction'][rxn[0]]\n",
    "                    i += 1\n",
    "                \n",
    "            elif response.status_code != 200:\n",
    "                response=session.get('http://bigg.ucsd.edu/universal/reactions/'+reactions['Reaction'][rxn[1]])\n",
    "                if response.status_code == 200:\n",
    "                    if reactions['Reaction'][rxn[0]] == rxns_attributes['Reaction'][rxn[0]] and reactions.loc[rxn[1], 'Reaction'] == rxns_attributes.loc[rxn[1], 'Reaction']:\n",
    "                        print(f'4 Reaction {reactions.iloc[rxn[0],6]} changed for {reactions.iloc[rxn[1],6]} present BiGG database')\n",
    "                        reactions.loc[rxn[0], 'Reaction'] = reactions['Reaction'][rxn[1]]\n",
    "                        rxns_attributes.loc[rxn[0], 'Reaction'] = rxns_attributes['Reaction'][rxn[1]]\n",
    "                        i += 1\n",
    "                elif response.status_code != 200:\n",
    "                    if reactions['Reaction'][rxn[0]] == rxns_attributes['Reaction'][rxn[0]] and reactions.loc[rxn[1], 'Reaction'] == rxns_attributes.loc[rxn[1], 'Reaction']:\n",
    "                        print(f'5 Reaction {reactions.iloc[rxn[1],6]} changed for {reactions.iloc[rxn[0],6]} not present in Bigg DB')\n",
    "                        reactions.loc[rxn[1], 'Reaction'] = reactions['Reaction'][rxn[0]]\n",
    "                        rxns_attributes.loc[rxn[1], 'Reaction'] = rxns_attributes['Reaction'][rxn[0]]\n",
    "                        i += 1\n",
    "\n",
    "print(len(duplicated_reactions))\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f770d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the original column order\n",
    "column_order_rxns = reactions.columns.tolist()\n",
    "column_order_att = rxns_attributes.columns.tolist()\n",
    "\n",
    "# Group by 'BiGG ID' and keep the first non-null value in each group, then reset the index\n",
    "reactions = reactions.groupby('Reaction').first().reset_index()\n",
    "rxns_attributes = rxns_attributes.groupby('Reaction').first().reset_index()\n",
    "\n",
    "# Rearrange the columns to the original order\n",
    "reactions = reactions[column_order_rxns]\n",
    "rxns_attributes = rxns_attributes[column_order_att]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3f7f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "reactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b641c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################\n",
    "#### ---------------------------------------------------- ####\n",
    "#### ---- Update Rxns and  Attributes Google Sheets ----- ####\n",
    "#### ---------------------------------------------------- ####\n",
    "##############################################################\n",
    "sheet.update_google_sheet(sheet_rxns, reactions)\n",
    "sheet.update_google_sheet(sheet_attributes, rxns_attributes)\n",
    "print(\"Google Sheet updated.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a101d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that Reactions IDs and formulas are equal in \"Rxns\" and \"Attributes\" sheets\n",
    "reactions = sheet.read_google_sheet(sheet_rxns)\n",
    "rxns_attributes = sheet.read_google_sheet(sheet_attributes)\n",
    "\n",
    "rxnsIDseq = list(reactions['Reaction']) == list(rxns_attributes['Reaction'])\n",
    "if rxnsIDseq:\n",
    "    print('Reaction IDs in the Rxns and Attributes Sheets are equal\\n')\n",
    "else:\n",
    "    rxns_sheet_ids = set(list(reactions['Reaction']))\n",
    "    attr_sheet_ids = set(list(rxns_attributes['Reaction']))\n",
    "    print(f'Reaction IDs that are in Rxns Sheet and not in Attributes Sheet {rxns_sheet_ids - attr_sheet_ids}\\n')\n",
    "    print(f'Reaction IDs that are in Attributes Sheet and not in Rxns Sheet {attr_sheet_ids - rxns_sheet_ids}\\n')\n",
    "\n",
    "rxnsforseq = list(reactions['Reaction Formula']) == list(rxns_attributes['Reaction Formula'])\n",
    "if rxnsforseq:\n",
    "    print('Reaction Formulas in the Rxns and Attributes Sheets are equal')\n",
    "else:\n",
    "    rxns_sheet_forms = set(list(reactions['Reaction Formula']))\n",
    "    attr_sheet_forms = set(list(rxns_attributes['Reaction Formula']))\n",
    "    print(f'Reaction formulas that are in Rxns Sheet and not in Attributes Sheet {rxns_sheet_forms - attr_sheet_forms}\\n')\n",
    "    print(f'Reaction formulas that are in Attributes Sheet and not in Rxns Sheet {attr_sheet_forms - rxns_sheet_forms}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "161f5a3e",
   "metadata": {},
   "source": [
    "## 3. Add Database links and Pre-checks to \"Rxns\" and \"Attributes\" Sheet <a id='bigg'></a>\n",
    "This section of the notebook is design to add extra features in the dataset without comprimising previous data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67192b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries import\n",
    "import time\n",
    "import requests\n",
    "import pandas as pd\n",
    "# from requests_html import HTMLSession\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from utils import duplicated_reactions\n",
    "from google_sheet import GoogleSheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cbe6c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the necessary datasets\n",
    "KEY_FILE_PATH = 'credentials.json'\n",
    "SPREADSHEET_ID_v3 = # Read from file\n",
    "\n",
    "# Initialize the GoogleSheet object\n",
    "sheet = GoogleSheet(SPREADSHEET_ID_v3, KEY_FILE_PATH)\n",
    "\n",
    "# Read data from the Google Sheet\n",
    "sheet_rxns = 'Rxns'\n",
    "sheet_attributes = 'Attributes'\n",
    "\n",
    "reactions = sheet.read_google_sheet(sheet_rxns)\n",
    "rxns_attributes = sheet.read_google_sheet(sheet_attributes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f860dabe",
   "metadata": {},
   "source": [
    "### 3.1 Add BiGG and EBI links to the \"Rxns\" and \"Attributes\" Sheets\n",
    "The functions created **fetch_url** and **extract_ec_numbers** check and retrieve information from the BiGG database. If the queried reaction is in BiGG, the link to the reaction is added to the **BiGG database** column of the **\"Rxns\" Sheet\"**. If the reaction also has an EC Number in the BiGG page, the **extract_ec_numbers** function retrieves this information to be added to the **EC Number** column of the **\"Attributes\" Sheet**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4133c863",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define functions\n",
    "\n",
    "def fetch_url(url, max_retries=5):\n",
    "    \"\"\"\n",
    "    Fetches a given URL and attempts to extract EC (Enzyme Commission)\n",
    "    numbers associated with reactions from the response.\n",
    "    \n",
    "    Parameters:\n",
    "    - url (str): The URL to fetch.\n",
    "    - max_retries (int, optional): The maximum number of retries if the request fails. Default is 5.\n",
    "\n",
    "    Returns:\n",
    "    - response (requests.models.Response or None): The server's response to the request.\n",
    "    Returns None if the request fails.\n",
    "    - ec_numbers (tuple or None): A tuple containing extracted EC numbers as strings and their corresponding links.\n",
    "    Returns None if no EC numbers are found or if the request fails.\n",
    "\n",
    "    Note:\n",
    "    If the server responds with a status code other than 200, both the response and ec_numbers will be set to None.\n",
    "    \"\"\"\n",
    "        \n",
    "    session = HTMLSession()\n",
    "    retries = 0\n",
    "    while retries < max_retries:\n",
    "        try:\n",
    "            response = session.get(url)\n",
    "            if response.status_code == 200:\n",
    "                ec_numbers = extract_ec_numbers(response)\n",
    "                return response,ec_numbers\n",
    "            elif response.status_code != 200:\n",
    "                response = None\n",
    "                ec_numbers = None\n",
    "                return response,ec_numbers\n",
    "            else:\n",
    "                retries += 1\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Error occurred: {e}, retrying...\")\n",
    "            retries += 1\n",
    "            time.sleep(2)  # wait for 2 seconds before next retry\n",
    "            response = None\n",
    "            ec_numbers = None\n",
    "    return response,ec_numbers\n",
    "\n",
    "def extract_ec_numbers(response):\n",
    "    \"\"\"\n",
    "    Extracts EC (Enzyme Commission) numbers and their corresponding links from the HTML content\n",
    "    of a given server response.\n",
    "    \n",
    "    Parameters:\n",
    "    - response (requests.models.Response): The server's response containing the HTML content.\n",
    "\n",
    "    Returns:\n",
    "    - ec_numbers_string (str or None): A string containing the extracted EC numbers separated by commas.\n",
    "    Returns None if no EC numbers are found.\n",
    "    - ec_links_string (str or None): A string containing the links associated with the extracted EC numbers,\n",
    "    separated by commas. Returns None if no EC numbers are found.\n",
    "\n",
    "    Note:\n",
    "    If the provided response does not contain any EC numbers, this function will print a message\n",
    "    stating 'No EC Number associated with this rxns in BiGG' and return None for both the EC numbers\n",
    "    and their links.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize BeautifulSoup with the response content\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    # Find all elements containing EC Numbers\n",
    "    ec_number_elements = soup.find_all('a', href=lambda x: x and 'ec-code' in x)\n",
    "    \n",
    "    if len(ec_number_elements) == 0:\n",
    "        print('No EC Number asociated with this rxns in BiGG')\n",
    "        return None\n",
    "    \n",
    "    elif len(ec_number_elements) > 0:\n",
    "        # Create a list to hold the EC Numbers and their links\n",
    "        ec_numbers = []\n",
    "        ec_links = []\n",
    "\n",
    "        for element in ec_number_elements:\n",
    "            # Extract the EC Number from the text of the element\n",
    "            ec_number = element.text.strip()\n",
    "            ec_numbers.append(ec_number)\n",
    "            # Extract the link from the href attribute of the element\n",
    "            link = element['href']\n",
    "            ec_links.append(link)\n",
    "        \n",
    "        ec_numbers_string = ', '.join(ec_numbers)\n",
    "        ec_links_string = ', '.join(ec_links)\n",
    "\n",
    "        return ec_numbers_string, ec_links_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d8aecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create df copies to be compared before the update of the dataset\n",
    "og_reactions = reactions.copy()\n",
    "og_rxns_attributes = rxns_attributes.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4b337a",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_chov1=0\n",
    "in_bigg=0\n",
    "not_bigg=0\n",
    "\n",
    "for i,row in reactions.iterrows():\n",
    "    rxn=row['Reaction']\n",
    "    response_esp, ec_data_esp = fetch_url('http://bigg.ucsd.edu/models/iCHOv1/reactions/'+rxn)\n",
    "    \n",
    "    if response_esp is not None:\n",
    "        print(rxn,'in CHOv1')\n",
    "        reactions.loc[i, 'BiGG database'] = 'http://bigg.ucsd.edu/models/iCHOv1/reactions/'+rxn\n",
    "        if rxns_attributes.loc[i,'EC Number']=='':\n",
    "            if ec_data_esp:\n",
    "                rxns_attributes.loc[i,'EC Number'] = ec_data_esp[0]\n",
    "                rxns_attributes.loc[i,'EC Number Link'] = ec_data_esp[1]\n",
    "                print(f'{rxn} EC Number found: {ec_data_esp[0]}, {ec_data_esp[1]}')\n",
    "        in_chov1+=1\n",
    "        \n",
    "    else:\n",
    "        response_gen, ec_data_gen = fetch_url('http://bigg.ucsd.edu/universal/reactions/'+rxn)\n",
    "        if response_gen is not None:\n",
    "            print(rxn,'in Bigg')\n",
    "            reactions.loc[i, 'BiGG database'] = 'http://bigg.ucsd.edu/universal/reactions/'+rxn\n",
    "            if rxns_attributes.loc[i,'EC Number']=='':\n",
    "                if ec_data_gen:\n",
    "                    rxns_attributes.loc[i,'EC Number'] = ec_data_gen[0]\n",
    "                    rxns_attributes.loc[i,'EC Number Link'] = ec_data_gen[1]\n",
    "                    print(f'{rxn} EC Number found: {ec_data_gen[0]}, {ec_data_gen[1]}')\n",
    "            in_bigg+=1\n",
    "        else:\n",
    "            print(rxn,'not in Bigg')\n",
    "            not_bigg+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332f2c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Reactions from CHOv1 reconstruction {in_chov1}')\n",
    "print(f'Reactions in BiGG database {in_bigg} [not including those in CHOv1)')\n",
    "print(f'Reactions NOT in BiGG {not_bigg}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253cd563",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################\n",
    "#### -------------------------------------------------- ####\n",
    "#### ---- Update Rxns and Attributes Google Sheet ----- ####\n",
    "#### -------------------------------------------------- ####\n",
    "############################################################\n",
    "if not og_reactions.equals(reactions):\n",
    "    sheet.update_google_sheet(sheet_rxns, reactions)\n",
    "    print(\"Rxns Sheet updated\")\n",
    "if not og_rxns_attributes.equals(rxns_attributes):\n",
    "    sheet.update_google_sheet(sheet_attributes, rxns_attributes)\n",
    "    print(\"Attributes Sheet updated.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a803e997",
   "metadata": {},
   "source": [
    "### 3.2 Add a \"Pre-check\" tag to the Rxns Sheet\n",
    "Here we add a \"Pre-check\" tag to those reactions that don't have a GPR annotation in any of the previous reconstructions. The aim of this is to facilitate the manual curation effort by providing a tag to those reaction that are relatively difficult to curate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a6f6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create df copies to be compared before the update of the dataset\n",
    "og_reactions = reactions.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f839d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update reactions df\n",
    "counter = 0\n",
    "for i,row in reactions.iterrows():\n",
    "    curated = row['Curated']\n",
    "    gpr_hef = row['GPR_hef']\n",
    "    gpr_fou = row['GPR_fou']\n",
    "    gpr_yeo = row['GPR_yeo']\n",
    "    gpr_recon = row['GPR_Recon3D']\n",
    "    gpr_final = row['GPR_final']\n",
    "    if (curated == '') and (gpr_hef == '') and (gpr_fou == '') and (gpr_yeo == '') and (gpr_recon == '') and (gpr_final == ''):\n",
    "        reactions.loc[i,'Curated'] = 'Pre-check'\n",
    "        reactions.loc[i,'Conf. Score'] = '1'\n",
    "        counter+=1\n",
    "        \n",
    "print(f'Total number of Pre-check reactions:{counter}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1e4096",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################\n",
    "#### ----------------------------------- ####\n",
    "#### ---- Update Rxns Google Sheet ----- ####\n",
    "#### ----------------------------------- ####\n",
    "#############################################\n",
    "\n",
    "if not og_reactions.equals(reactions): # checks if there has been any update on the original dataset\n",
    "    sheet.update_google_sheet(sheet_rxns, reactions)\n",
    "    print(\"Rxns Sheet updated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b777e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "814278b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5877ba6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e77fd01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e43fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load df containing all the reactions and a \"x\" mark indicating from which CHO recon each reaction comes from\n",
    "all_dfs3 = pd.read_excel('../Data/Reconciliation/datasets/all_dfs3.xlsx')\n",
    "if 'Unnamed: 0' in all_dfs3.columns:\n",
    "    all_dfs3 = all_dfs3.drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8ee20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load df containing all the recon3d reactions\n",
    "recon3d = pd.read_excel('../Data/Reconciliation/datasets/recon3D_all_reactions.xlsx')\n",
    "if 'Unnamed: 0' in recon3d.columns:\n",
    "    recon3d = recon3d.drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9762e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate listS with all the reactions present in the three CHO reconstructions\n",
    "rxns_list = []\n",
    "rxns_hef_list = []\n",
    "rxns_fou_list = []\n",
    "rxns_yeo_list = []\n",
    "for i,row in all_dfs3.iterrows():\n",
    "    if row['hef']=='X' and row['fou']=='X' and row['yeo']=='X':\n",
    "        rxns_list.append(row['Reaction'])\n",
    "    if row['hef']=='X':\n",
    "        rxns_hef_list.append(row['Reaction'])\n",
    "    if row['fou']=='X':\n",
    "        rxns_fou_list.append(row['Reaction'])\n",
    "    if row['yeo']=='X':\n",
    "        rxns_yeo_list.append(row['Reaction'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d1b76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a list with all the reactions present in the three CHO reconstructions\n",
    "rxns_recon3d_list = list(recon3d['m_reaction'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1cb271",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update reactions df\n",
    "counter = 0\n",
    "for i,row in reactions.iterrows():\n",
    "    rxn=row['Reaction']\n",
    "    curated = row['Curated']\n",
    "    gpr_hef = row['GPR_hef']\n",
    "    gpr_fou = row['GPR_fou']\n",
    "    gpr_yeo = row['GPR_yeo']\n",
    "    gpr_recon = row['GPR_Recon3D']\n",
    "    gpr_final = row['GPR_final']\n",
    "    \n",
    "    if (rxn in rxns_hef_list):\n",
    "        reactions.loc[i,'iCHO1766'] = 'X'\n",
    "    else:\n",
    "        reactions.loc[i,'iCHO1766'] = '-'\n",
    "    if (rxn in rxns_fou_list):\n",
    "        reactions.loc[i,'iCH02101'] = 'X'\n",
    "    else:\n",
    "        reactions.loc[i,'iCH02101'] = '-'\n",
    "    if (rxn in rxns_yeo_list):\n",
    "        reactions.loc[i,'iCHO2291'] = 'X'\n",
    "    else:\n",
    "        reactions.loc[i,'iCHO2291'] = '-'\n",
    "    if (rxn in rxns_recon3d_list):\n",
    "        reactions.loc[i,'RECON3D'] = 'X'\n",
    "    else:\n",
    "        reactions.loc[i,'RECON3D'] = '-'\n",
    "\n",
    "    if (curated == '') and (rxn in rxns_list) and (gpr_hef == '') and (gpr_fou == '') and (gpr_yeo == '') and (gpr_recon == '') and (gpr_final == ''):\n",
    "        reactions.loc[i,'Curated'] = 'Pre-check(CHO)'\n",
    "        reactions.loc[i,'Conf. Score'] = '1'\n",
    "    elif (curated == '') and (rxn in rxns_hef_list) and (rxn in rxns_recon3d_list) and (gpr_hef == '') and (gpr_fou == '') and (gpr_yeo == '') and (gpr_recon == '') and (gpr_final == ''):\n",
    "        reactions.loc[i,'Curated'] = 'Pre-check(Hefzi_RECON)'\n",
    "        reactions.loc[i,'Conf. Score'] = '1'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8806454b",
   "metadata": {},
   "source": [
    "## 4. Subsystem Reorganization <a id='subsystem'></a>\n",
    "Update on the subsystem organization of our reconstruction. Subsystems are organized according to Anne's dataset based on the reorganization performed in iCHO1766. Also, each susbsytem is assigned to a larger system conting many subsystems of the same characteristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5ea43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "from google_sheet import GoogleSheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1537a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the necessary datasets\n",
    "KEY_FILE_PATH = 'credentials.json'\n",
    "SPREADSHEET_ID_v3 = '1MlBXeHIKw8k8fZyXm-sN__AHTRSunJxar_-bqvukZws'\n",
    "\n",
    "# Initialize the GoogleSheet object\n",
    "sheet = GoogleSheet(SPREADSHEET_ID_v3, KEY_FILE_PATH)\n",
    "\n",
    "# Read data from the Google Sheet\n",
    "sheet_rxns = 'Rxns'\n",
    "\n",
    "reactions = sheet.read_google_sheet(sheet_rxns)\n",
    "reactions_dc = reactions.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b7a7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subsystems Reorganization Dataset\n",
    "subsystems = pd.read_excel('../Data/Subsystem/Systems.xlsx', 'iCHO1766_cleaned')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a584d193",
   "metadata": {},
   "source": [
    "### 4.1 Update Transport reactions\n",
    "Transport reactions subsystem reorganization is based on the compartment to wich each metabolite is transported to/from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a42b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,rxn in reactions_dc.iterrows():\n",
    "    if rxn['Subsystem'] == 'TRANSPORT':\n",
    "        if '_e' in rxn['Reaction Formula']:\n",
    "            print('TRANSPORT, EXTRACELLULAR',rxn['Reaction Formula'])\n",
    "            reactions_dc.loc[i,'Subsystem'] = 'TRANSPORT, EXTRACELLULAR'\n",
    "        elif '_m' in rxn['Reaction Formula']:\n",
    "            print('TRANSPORT, MITOCHONDRIAL',rxn['Reaction Formula'])\n",
    "            reactions_dc.loc[i,'Subsystem'] = 'TRANSPORT, MITOCHONDRIAL'\n",
    "        elif '_g' in rxn['Reaction Formula']:\n",
    "            print('TRANSPORT, GOLGI APPARATUS',rxn['Reaction Formula'])\n",
    "            reactions_dc.loc[i,'Subsystem'] = 'TRANSPORT, GOLGI APPARATUS'\n",
    "        elif '_r' in rxn['Reaction Formula']:\n",
    "            print('TRANSPORT, ENDOPLASMIC RETICULAR',rxn['Reaction Formula'])\n",
    "            reactions_dc.loc[i,'Subsystem'] = 'TRANSPORT, ENDOPLASMIC RETICULAR'\n",
    "        elif '_l' in rxn['Reaction Formula']:\n",
    "            print('TRANSPORT, LYSOSOMAL',rxn['Reaction Formula'])\n",
    "            reactions_dc.loc[i,'Subsystem'] = 'TRANSPORT, LYSOSOMAL'\n",
    "        elif '_n' in rxn['Reaction Formula']:\n",
    "            print('TRANSPORT, NUCLEAR',rxn['Reaction Formula'])\n",
    "            reactions_dc.loc[i,'Subsystem'] = 'TRANSPORT, NUCLEAR'\n",
    "        elif '_x' in rxn['Reaction Formula']:\n",
    "            print('TRANSPORT, PEROXISOMAL',rxn['Reaction Formula'])\n",
    "            reactions_dc.loc[i,'Subsystem'] = 'TRANSPORT, PEROXISOMAL'\n",
    "        else:\n",
    "            raise Exception(f\"Compartment unidentified for {rxn['Reaction Formula']}\")\n",
    "\n",
    "rxns_equals = reactions_dc.equals(reactions)\n",
    "if not rxns_equals:\n",
    "    sheet.update_google_sheet(sheet_rxns, reactions_dc)\n",
    "    print(\"Google Sheet updated.\")\n",
    "elif rxns_equals:\n",
    "    print(\"Transport Reactions are up-to-date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e7d967",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save previous subsystem organization as a python dict.\n",
    "\n",
    "#reaction_dict = reactions_dc.set_index('Reaction')['Subsystem'].to_dict()\n",
    "\n",
    "# Save dictionary as a pickle file\n",
    "#pickle_file = '../Data/Subsystem/reaction_oldsubsystem_dict.pkl'\n",
    "#with open(pickle_file, 'wb') as file:\n",
    "#    pickle.dump(reaction_dict, file)\n",
    "\n",
    "#pickle_file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b02d18",
   "metadata": {},
   "source": [
    "### 4.2 Update iCHO1766 Reactions Subsystem\n",
    "First we update the subsystems of all the reactions extracte from iCHO1766 based on the subsystems annotated in the subsystem dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b514c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Update subsystems in iCHO1766 reactions based on the new reorganization\n",
    "for i_1,rxn in enumerate(reactions_dc['Reaction']):\n",
    "    for i_2,rxn2 in enumerate(subsystems['Reaction ID']):\n",
    "        if str(rxn2) == str(rxn):\n",
    "            subs1 = str(reactions_dc['Subsystem'][i_1])\n",
    "            subs2 = str(subsystems['Subsystem'][i_2])\n",
    "            if subs1 != subs2:\n",
    "                print('%s Old subsystem: %s --> New subsystem %s' % (rxn, subs1, subs2))\n",
    "                reactions_dc.at[i_1, 'Subsystem'] = subs2  # Update the subsystem\n",
    "                \n",
    "rxns_equals = reactions_dc.equals(reactions)\n",
    "if not rxns_equals:\n",
    "    sheet.update_google_sheet(sheet_rxns, reactions_dc)\n",
    "    print(\"Google Sheet updated.\")\n",
    "elif rxns_equals:\n",
    "    print(\"Subsystem reorganization is up-to-date\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b786bdee",
   "metadata": {},
   "source": [
    "### 4.3 Manual Standarization of Subsystems\n",
    "The rest of the subsystems that have not been changed in the previous code are manually standarize in order to comply with the new organization based on the \"Systems.xslx\" dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c84385e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, we unify all the Fatty Acids subsystems into FATTY ACID METABOLISM\n",
    "for i,rxn in reactions_dc.iterrows():\n",
    "    if rxn['Subsystem'] == 'FATTY ACID OXIDATION':\n",
    "        reactions_dc.loc[i,'Subsystem'] = 'FATTY ACID METABOLISM'\n",
    "    elif rxn['Subsystem'] == 'FATTY ACID SYNTHESIS':\n",
    "        reactions_dc.loc[i,'Subsystem'] = 'FATTY ACID METABOLISM'\n",
    "    elif rxn['Subsystem'] == 'FATTY ACID ELONGATION':\n",
    "        reactions_dc.loc[i,'Subsystem'] = 'FATTY ACID METABOLISM'\n",
    "\n",
    "rxns_equals = reactions_dc.equals(reactions)\n",
    "if not rxns_equals:\n",
    "    sheet.update_google_sheet(sheet_rxns, reactions_dc)\n",
    "    print(\"Google Sheet updated.\")\n",
    "elif rxns_equals:\n",
    "    print(\"Fatty Acid reorganization is up-to-date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c631000",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second, we standarize  'PURINE CATABOLISM and SYNTHESIS', PYRIMIDINE CATABOLISM and SYNTHESIS' in PURINE/PYRIMIDINE METABOLISM\n",
    "for i,rxn in reactions_dc.iterrows():\n",
    "    if rxn['Subsystem'] == 'PURINE CATABOLISM':\n",
    "        reactions_dc.loc[i,'Subsystem'] = 'PURINE METABOLISM'\n",
    "    elif rxn['Subsystem'] == 'PURINE SYNTHESIS':\n",
    "        reactions_dc.loc[i,'Subsystem'] = 'PURINE METABOLISM'\n",
    "    elif rxn['Subsystem'] == 'PYRIMIDINE CATABOLISM':\n",
    "        reactions_dc.loc[i,'Subsystem'] = 'PYRIMIDINE METABOLISM'\n",
    "    elif rxn['Subsystem'] == 'PYRIMIDINE SYNTHESIS':\n",
    "        reactions_dc.loc[i,'Subsystem'] = 'PYRIMIDINE METABOLISM'\n",
    "\n",
    "rxns_equals = reactions_dc.equals(reactions)\n",
    "if not rxns_equals:\n",
    "    sheet.update_google_sheet(sheet_rxns, reactions_dc)\n",
    "    print(\"Google Sheet updated.\")\n",
    "elif rxns_equals:\n",
    "    print(\"PURINE and PYRIMIDINE reorganization is up-to-date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8154e9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Third, we standarize 'HEME DEGRADATION' AND 'HEME SYNTHESIS' into 'HEME METABOLISM'\n",
    "for i,rxn in reactions_dc.iterrows():\n",
    "    if rxn['Subsystem'] == 'HEME DEGRADATION':\n",
    "        reactions_dc.loc[i,'Subsystem'] = 'HEME METABOLISM'\n",
    "    elif rxn['Subsystem'] == 'HEME SYNTHESIS':\n",
    "        reactions_dc.loc[i,'Subsystem'] = 'HEME METABOLISM'\n",
    "\n",
    "rxns_equals = reactions_dc.equals(reactions)\n",
    "if not rxns_equals:\n",
    "    sheet.update_google_sheet(sheet_rxns, reactions_dc)\n",
    "    print(\"Google Sheet updated.\")\n",
    "elif rxns_equals:\n",
    "    print(\"HEME reorganization is up-to-date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c57d9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fourth, we change the O-GLYCAN and N-GLYCAN subsystems according to Systems dataset\n",
    "for i,rxn in reactions_dc.iterrows():\n",
    "    if rxn['Subsystem'] == 'N-GLYCAN BIOSYNTHESIS':\n",
    "        reactions_dc.loc[i,'Subsystem'] = 'N-GLYCAN METABOLISM'\n",
    "    elif rxn['Subsystem'] == 'O-GLYCAN METABOLISM':\n",
    "        reactions_dc.loc[i,'Subsystem'] = 'O-GLYCAN SYNTHESIS'\n",
    "\n",
    "rxns_equals = reactions_dc.equals(reactions)\n",
    "if not rxns_equals:\n",
    "    sheet.update_google_sheet(sheet_rxns, reactions_dc)\n",
    "    print(\"Google Sheet updated.\")\n",
    "elif rxns_equals:\n",
    "    print(\"O-GLYCAN and N-GLYCAN reorganization is up-to-date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a6759b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fifth, we standarize the 'COA CATABOLISM' and 'COA SYNTHESIS'into 'COA METABOLISM'\n",
    "for i,rxn in reactions_dc.iterrows():\n",
    "    if rxn['Subsystem'] == 'COA CATABOLISM':\n",
    "        reactions_dc.loc[i,'Subsystem'] = 'COA METABOLISM'\n",
    "    elif rxn['Subsystem'] == 'COA SYNTHESIS':\n",
    "        reactions_dc.loc[i,'Subsystem'] = 'COA METABOLISM'\n",
    "\n",
    "rxns_equals = reactions_dc.equals(reactions)\n",
    "if not rxns_equals:\n",
    "    sheet.update_google_sheet(sheet_rxns, reactions_dc)\n",
    "    print(\"Google Sheet updated.\")\n",
    "elif rxns_equals:\n",
    "    print(\"COA reorganization is up-to-date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a96a795",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sixth, we include 'KERATAN SULFATE DEGRADATION' in 'KERATAN SULFATE METABOLISM'\n",
    "for i,rxn in reactions_dc.iterrows():\n",
    "    if rxn['Subsystem'] == 'KERATAN SULFATE DEGRADATION':\n",
    "        reactions_dc.loc[i,'Subsystem'] = 'KERATAN SULFATE METABOLISM'\n",
    "\n",
    "rxns_equals = reactions_dc.equals(reactions)\n",
    "if not rxns_equals:\n",
    "    sheet.update_google_sheet(sheet_rxns, reactions_dc)\n",
    "    print(\"Google Sheet updated.\")\n",
    "elif rxns_equals:\n",
    "    print(\"KERATAN SULFATE reorganization is up-to-date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934483b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, we standarize the BIOMASS AND 'MISCELLANEOUS' subsystems according to the new organization\n",
    "for i,rxn in reactions_dc.iterrows():\n",
    "    if rxn['Subsystem'] == 'BIOMASS AND MAINTENANCE FUNCTIONS':\n",
    "        reactions_dc.loc[i,'Subsystem'] = 'BIOMASS'\n",
    "    elif rxn['Subsystem'] == 'BIOMASS SYNTHESIS':\n",
    "        reactions_dc.loc[i,'Subsystem'] = 'BIOMASS'\n",
    "    elif rxn['Subsystem'] == 'MISCELLANEOUS':\n",
    "        reactions_dc.loc[i,'Subsystem'] = 'UNASSIGNED'\n",
    "\n",
    "        \n",
    "rxns_equals = reactions_dc.equals(reactions)\n",
    "if not rxns_equals:\n",
    "    sheet.update_google_sheet(sheet_rxns, reactions_dc)\n",
    "    print(\"Google Sheet updated.\")\n",
    "elif rxns_equals:\n",
    "    print(\"BIOMASS and 'MISCELLANEOUS' reactions reorganization is up-to-date\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b316d23",
   "metadata": {},
   "source": [
    "### 4.4 Check for differences in the Subsystems of the Reconstrction and Systems datasets\n",
    "Here we check for differences after all the modifications. Some of these differences can be fixed manually and others can be kept as new subsystems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500bdffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "AR_subsystems = set(subsystems['Subsystem'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c5cd94",
   "metadata": {},
   "outputs": [],
   "source": [
    "Reconstruction_subsystems = set(reactions_dc['Subsystem'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0b9525",
   "metadata": {},
   "outputs": [],
   "source": [
    "shared_subsystems = Reconstruction_subsystems.intersection(AR_subsystems)\n",
    "print(len(shared_subsystems), shared_subsystems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd29aade",
   "metadata": {},
   "outputs": [],
   "source": [
    "AR_subsystems_unique = AR_subsystems.difference(Reconstruction_subsystems)\n",
    "Reconstruction_subsystems_unique = Reconstruction_subsystems.difference(AR_subsystems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d249526",
   "metadata": {},
   "outputs": [],
   "source": [
    "Reconstruction_subsystems_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f3e9e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "AR_subsystems_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "039e5992",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_counter = 0\n",
    "for index, reaction in reactions.iterrows():\n",
    "    if reaction['Subsystem'] in Reconstruction_subsystems_unique:\n",
    "        unique_counter += 1\n",
    "        print(unique_counter, reaction['Subsystem'], \", \", reaction['Reaction Name'], \", \", reaction['Reaction Formula'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac20ecef",
   "metadata": {},
   "source": [
    "## 5. Manual Curation Metrics <a id='curation'></a>\n",
    "Here we estimate and classify the amount of curated reactions in each tier of the updated version of the proposed work plan of the reaconstruction: https://docs.google.com/document/d/1C9iJx2F5Om5pTk5607naa9cluA6x8BzC7dqt1ybtg6A/edit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a69aaa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from google_sheet import GoogleSheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad16b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the necessary datasets\n",
    "KEY_FILE_PATH = 'credentials.json'\n",
    "SPREADSHEET_ID_v3 = '1MlBXeHIKw8k8fZyXm-sN__AHTRSunJxar_-bqvukZws'\n",
    "\n",
    "# Initialize the GoogleSheet object\n",
    "sheet = GoogleSheet(SPREADSHEET_ID_v3, KEY_FILE_PATH)\n",
    "\n",
    "# Read data from the Google Sheet\n",
    "sheet_rxns = 'Rxns'\n",
    "\n",
    "reactions = sheet.read_google_sheet(sheet_rxns)\n",
    "metric_reactions = reactions.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a295bea3",
   "metadata": {},
   "source": [
    "### 5.1 Calculate the amount of reactions in _max tier_\n",
    "_Max tier_ represents the most complete type of manual curation and it is based in New literature curation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d870b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_tier_counter = 0\n",
    "\n",
    "for i,r in metric_reactions.iterrows():\n",
    "    if (r['Curated'] != '') and (r['Curated'] != 'Pre-check') and (r['Curated'] != 'NOT CURATED') and (r['Curated'] != 'basic tier 1 (RxnsWithNotes)') and (r['Curated'] != 'basic tier 1 (Recon3DRxns)') and (r['Curated'] != 'basic tier 2 (AllRecons)') and (r['Curated'] != 'basic tier 2 (Recon3D&CHO)'):\n",
    "        notes = str(r['Curation Notes']).lower()\n",
    "        references = str(r['References']).lower()\n",
    "        if 'rhea' not in notes and 'rhea' not in references:\n",
    "            max_tier_counter += 1\n",
    "        \n",
    "print(max_tier_counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "909021b9",
   "metadata": {},
   "source": [
    "### 5.2 Calculate the amount of reactions in _medium tier_\n",
    "_Medium tier_ represents reactions that have been curated using the new approach basen on the Rheat database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aeb247e",
   "metadata": {},
   "outputs": [],
   "source": [
    "medium_tier_counter = 0\n",
    "\n",
    "for i,r in metric_reactions.iterrows():\n",
    "    if (r['Curated'] != '') and (r['Curated'] != 'Pre-check') and (r['Curated'] != 'NOT CURATED') and (r['Curated'] != 'basic tier 1 (RxnsWithNotes)') and (r['Curated'] != 'basic tier 1 (Recon3DRxns)') and (r['Curated'] != 'basic tier 2 (AllRecons)') and (r['Curated'] != 'basic tier 2 (Recon3D&CHO)'):\n",
    "        notes = str(r['Curation Notes']).lower()\n",
    "        references = str(r['References']).lower()\n",
    "        if 'rhea' in notes or 'rhea' in references:\n",
    "            medium_tier_counter += 1\n",
    "        \n",
    "print(medium_tier_counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9be683aa",
   "metadata": {},
   "source": [
    "### 5.3 Calculate the amount of reactions in _basic tier 1_\n",
    "_Basic tier 1_ comprises reactions with spot check of previous curation, Recon 3D reactions - porting of their curation + homology mapping of GPRs, Porting of Hefzi curation note, Acceptance of no-GPR reactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80d8a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-check reactions\n",
    "pre_check_counter = 0\n",
    "\n",
    "for i,r in metric_reactions.iterrows():\n",
    "    if r['Curated'] == 'Pre-check':\n",
    "        pre_check_counter += 1\n",
    "        \n",
    "print(pre_check_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b370c3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reactions not curated with notes\n",
    "notes_counter = 0\n",
    "\n",
    "for i, r in metric_reactions.iterrows():\n",
    "    # Strip leading/trailing whitespace and check if the result is not an empty string\n",
    "    if (r['Curated'] == '') and isinstance(r['Curation Notes'], str) and r['Curation Notes'].strip() != '':\n",
    "        notes_counter += 1\n",
    "        metric_reactions.loc[i,'Curated'] = 'basic tier 1 (RxnsWithNotes)'\n",
    "    elif r['Curated'] == 'basic tier 1 (RxnsWithNotes)':\n",
    "        notes_counter += 1\n",
    "\n",
    "print(notes_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26cc7f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reactions extracted from Recon 3D without notes\n",
    "recon3d_counter = 0\n",
    "\n",
    "for i, r in metric_reactions.iterrows():\n",
    "    if (r['RECON3D'] == 'X') and (r['iCHO1766'] == '-') and (r['iCH02101'] == '-') and (r['iCHO2291'] == '-'):\n",
    "        # Check if 'Curated' is empty or only contains whitespace\n",
    "        if pd.isnull(r['Curated']) or (isinstance(r['Curated'], str) and r['Curated'].strip() == ''):\n",
    "            # Check if 'Curation Notes' is empty or only contains whitespace\n",
    "            if pd.isnull(r['Curation Notes']) or (isinstance(r['Curation Notes'], str) and r['Curation Notes'].strip() == ''):\n",
    "                recon3d_counter += 1\n",
    "                metric_reactions.loc[i,'Curated'] = 'basic tier 1 (Recon3DRxns)'\n",
    "        elif r['Curated'] == 'basic tier 1 (Recon3DRxns)':\n",
    "            recon3d_counter += 1\n",
    "                \n",
    "\n",
    "print(recon3d_counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8215e3",
   "metadata": {},
   "source": [
    "### 5.4 Calculate the amount of reactions in _basic tier 2_\n",
    "_Basic tier 2_ is divided in two categories: \n",
    "1) Reactions with consistent reaction annotation in all the reconstructions. \n",
    "2) Reactions with consistent annotation in Recon3D and at least one CHO reconstruction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283b2bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reactions with consistent reaction annotation in all the reconstructions.\n",
    "basictier2_allrecons_counter = 0\n",
    "basictier2_allrecons_list = []\n",
    "\n",
    "for i, r in metric_reactions.iterrows():\n",
    "    if (r['RECON3D'] == 'X') and (r['iCHO1766'] == 'X') and (r['iCH02101'] == 'X') and (r['iCHO2291'] == 'X'):\n",
    "        # Check if 'Curated' is empty or only contains whitespace\n",
    "        if pd.isnull(r['Curated']) or (isinstance(r['Curated'], str) and r['Curated'].strip() == ''):\n",
    "            # Check if 'Curation Notes' is empty or only contains whitespace\n",
    "            if pd.isnull(r['Curation Notes']) or (isinstance(r['Curation Notes'], str) and r['Curation Notes'].strip() == ''):\n",
    "                basictier2_allrecons_counter += 1\n",
    "                basictier2_allrecons_list.append(r['Reaction'])\n",
    "                metric_reactions.loc[i,'Curated'] = 'basic tier 2 (AllRecons)'\n",
    "        elif r['Curated'] == 'basic tier 2 (AllRecons)':\n",
    "            basictier2_allrecons_list.append(r['Reaction'])\n",
    "            basictier2_allrecons_counter += 1\n",
    "            \n",
    "print(basictier2_allrecons_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b471bef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reactions with consistent annotation in Recon3D and at least one CHO reconstruction.\n",
    "basictier2_recon3d_counter = 0\n",
    "\n",
    "for i, r in metric_reactions.iterrows():\n",
    "    if (r['RECON3D'] == 'X') and ((r['iCHO1766'] == 'X') or (r['iCH02101'] == 'X') or (r['iCHO2291'] == 'X')):\n",
    "        # Check if 'Curated' is empty or only contains whitespace\n",
    "        if pd.isnull(r['Curated']) or (isinstance(r['Curated'], str) and r['Curated'].strip() == ''):\n",
    "            # Check if 'Curation Notes' is empty or only contains whitespace\n",
    "            if pd.isnull(r['Curation Notes']) or (isinstance(r['Curation Notes'], str) and r['Curation Notes'].strip() == ''):\n",
    "                if r['Reaction'] not in basictier2_allrecons_list:\n",
    "                    basictier2_recon3d_counter += 1\n",
    "                    metric_reactions.loc[i,'Curated'] = 'basic tier 2 (Recon3D&CHO)'\n",
    "        elif r['Curated'] == 'basic tier 2 (Recon3D&CHO)':\n",
    "            basictier2_recon3d_counter += 1\n",
    "            \n",
    "print(basictier2_recon3d_counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b867e537",
   "metadata": {},
   "source": [
    "### 5.5 Plot a Pie Chart with the amount of reactions in each tier\n",
    "_Basic tier 2_ represents reactions with consistent GPR annotation in all the reconstructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "595fb52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the number of reactions that are not curated\n",
    "not_curated = i - (max_tier_counter + medium_tier_counter + basictier2_allrecons_counter + basictier2_recon3d_counter + pre_check_counter + notes_counter + recon3d_counter)\n",
    "\n",
    "if not_curated > 0:\n",
    "    # Labels for the pie chart\n",
    "    labels = ['max tier', 'medium tier', 'basic tier 2 (All Recons)', 'basic tier 2 (Recon3D&CHO)', 'basic tier 1 (Pre-checked reactions)', 'basic tier 1 (Reactions with Notes)', 'basic tier 1 (Recon3D reactions)', 'Not curated']\n",
    "\n",
    "    # Sizes for each segment of the pie chart\n",
    "    sizes = [max_tier_counter, medium_tier_counter, basictier2_allrecons_counter, basictier2_recon3d_counter, pre_check_counter, notes_counter, recon3d_counter, not_curated]\n",
    "\n",
    "    # Colors for each segment\n",
    "    colors = ['gold', 'lightcoral', 'lightskyblue', 'lightgreen', 'orange', 'purple', 'grey', 'red']\n",
    "\n",
    "    # Exploding the 1st slice (i.e., 'max tier')\n",
    "    explode = (0, 0, 0, 0, 0, 0, 0, 0)  # Make sure this matches the number of entries in 'sizes'\n",
    "elif not_curated <= 0:\n",
    "    # Labels for the pie chart\n",
    "    labels = ['max tier', 'medium tier', 'basic tier 2 (All Recons)', 'basic tier 2 (Recon3D&CHO)', 'basic tier 1 (Pre-checked reactions)', 'basic tier 1 (Reactions with Notes)', 'basic tier 1 (Recon3D reactions)']\n",
    "\n",
    "    # Sizes for each segment of the pie chart\n",
    "    sizes = [max_tier_counter, medium_tier_counter, basictier2_allrecons_counter, basictier2_recon3d_counter, pre_check_counter, notes_counter, recon3d_counter]\n",
    "\n",
    "    # Colors for each segment\n",
    "    colors = ['gold', 'lightcoral', 'lightskyblue', 'lightgreen', 'orange', 'purple', 'grey']\n",
    "\n",
    "    # Exploding the 1st slice (i.e., 'max tier')\n",
    "    explode = (0, 0, 0, 0, 0, 0, 0)  # Make sure this matches the number of entries in 'sizes'\n",
    "\n",
    "# Plotting the pie chart\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.pie(sizes, explode=explode, labels=labels, colors=colors, autopct='%1.1f%%', startangle=140)\n",
    "plt.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
    "\n",
    "plt.savefig('../Comparison/manual_curation_piechart.png', dpi=300)  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0c6c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################\n",
    "#### ----------------------------------- ####\n",
    "#### ---- Update Rxns Google Sheet ----- ####\n",
    "#### ----------------------------------- ####\n",
    "#############################################\n",
    "\n",
    "if not metric_reactions.equals(reactions): # checks if there has been any update on the original dataset\n",
    "    sheet.update_google_sheet(sheet_rxns, metric_reactions)\n",
    "    print(\"Rxns Sheet updated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e5432b4-81a8-41a9-a188-36c1bd1d81b6",
   "metadata": {},
   "source": [
    "## 6. Addition of Kcat values added by Meiyas' team <a id='kcat'></a>\n",
    "Here we map all the MW, Kcat values and Kcat references obtained by Meiyas teams using Donghyuk's code. The following approach was carried out:\n",
    "1) Kcat values for irreversible reactions were taken from the reference sheet generated by the Python Script shared by Dong Hyuk and curation was done following the same hierarchy of organisms discussed previously. (EC_Number_to_Reactions_RefSheet)\n",
    "2) We extracted the values from the Recon 3 Curation sheet shared by Dr. Meiya for Reversible reactions. (Recon3_1_new)\n",
    "3) If appropriate values were not found in the above sources, we referred to the supplementary data from Yeo et al., 2020. (iCHOv2)\n",
    "\n",
    "For all the curated reactions, the corresponding reference organism and the referred source have been included. Appropriate comments are given if either of the Kcat values is not found (in case of reversible reactions) or the Kcat value is not reported for the same substrate. Please look into the attached curation sheet and let me know your feedback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7abda73-6aea-471f-9cef-e2cd56042dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "from google_sheet import GoogleSheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d19c37e7-93cf-443a-bfe2-38bfc4e627aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppress the specific FutureWarning\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning, message=\"Downcasting behavior in `replace` is deprecated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be967c6-79f6-48dd-a2b5-05158509d30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the necessary datasets\n",
    "KEY_FILE_PATH = 'credentials.json'\n",
    "SPREADSHEET_ID_v3 = '1MlBXeHIKw8k8fZyXm-sN__AHTRSunJxar_-bqvukZws'\n",
    "\n",
    "# Initialize the GoogleSheet object\n",
    "sheet = GoogleSheet(SPREADSHEET_ID_v3, KEY_FILE_PATH)\n",
    "\n",
    "# Read data from the Google Sheet\n",
    "attributes_sheet = 'Attributes'\n",
    "\n",
    "attributes = sheet.read_google_sheet(attributes_sheet)\n",
    "attributes_copy = attributes.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973f53cd-b24d-488e-a902-7e5f0fd62293",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the kcat values dataset\n",
    "kcat_values = pd.read_excel('../Data/kcat_values/CHO_MW_kcat Curation.xlsx')\n",
    "# Generate a dict with using the reactions IDs as keys and the MW, kcat_forward, kcat_backward, kcat Reference and Comments as subkeys\n",
    "kcat_values_dict = kcat_values.set_index('Reaction')[['Mol wt', 'kcat_forward', 'kcat_backward', 'kcat Reference', 'Comments']].to_dict('index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ecab43-521d-4311-961a-de0099aaa70c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Map the values from the reaction_dict to the attributes_df\n",
    "for reaction in kcat_values_dict:\n",
    "    if reaction in attributes_copy['Reaction'].values:\n",
    "        attributes_copy.loc[attributes_copy['Reaction'] == reaction, ['Mol wt', 'kcat_forward', 'kcat_backward', 'kcat Reference', 'Comments']] = \\\n",
    "        attributes_copy.loc[attributes_copy['Reaction'] == reaction, ['Mol wt', 'kcat_forward', 'kcat_backward', 'kcat Reference', 'Comments']].replace('', kcat_values_dict[reaction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ded8a9-670e-4d42-8637-71e3215d8580",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################\n",
    "#### ----------------------------------------- ####\n",
    "#### ---- Update Attributes Google Sheet ----- ####\n",
    "#### ----------------------------------------- ####\n",
    "###################################################\n",
    "\n",
    "if not attributes_copy.equals(attributes): # checks if there has been any update on the original dataset\n",
    "    sheet.update_google_sheet(attributes_sheet, attributes_copy)\n",
    "    print(\"Attributes Sheet updated with kcat values\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GEM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
